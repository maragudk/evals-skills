# evals-skills

<img src="logo.png" alt="Logo" width="300" align="right">

Skills for AIs to do evals, error analysis, and more.

## Usage

You can install skills using [the `skills` tool](https://skills.sh):

```sh
npx skills add maragudk/evals-skills
```

## Available skills

- **failure-taxonomy** - Build a structured taxonomy of failure modes from open-coded trace annotations (axial coding)
- **llm-as-a-judge** - Build, validate, and deploy LLM-as-Judge evaluators for automated quality assessment of LLM pipeline outputs
- **prompt-engineering** - Craft, review, and improve prompts for LLM pipelines, including task prompts, system prompts, and LLM-as-Judge prompts
- **trace-annotation-tool** - Generate a custom trace annotation web app for open coding during LLM error analysis
